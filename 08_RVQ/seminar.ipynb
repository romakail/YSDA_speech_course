{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["In this assignment we are going to explore vector quantization and different sorts of it. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "\n", "import lightning as L\n", "import torch\n", "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%load_ext tensorboard"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%load_ext autoreload\n", "%reload_ext autoreload\n", "%autoreload 2\n", "%matplotlib inline\n", "\n", "from data import *\n", "from model import *\n", "from tests import *\n", "from vector_quantization import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device_id = 7\n", "device = torch.device(f\"cuda:{device_id}\" if device_id >= 0 else torch.device(\"cpu\"))\n", "\n", "data_path = Path(\"../data/08_RVQ\")\n", "data_path.mkdir(exist_ok=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1. Training loop\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To start with, we are going to train an encoder-decoder model to have something to compare with.\n", "The encoder-decoder model is implemented in file `model.py`, it consists of simple convolutional residual blocks.\n", "We'll train on MNIST dataset, images of size `[1 x 28 x 28]`.\n", "Then encode them into size `[1 x 3 x 3]`, then decode it back."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this assignment, we are going to use lightning, as it is a fast and easy way to organize training loop, logging, checkpointing and so on... It assembles of 3 parts, majority of which are implemented for you.\n", "- `DataModule`. This is a class, which does the data management: downloading, train-test splitting, loaders creation. It is implemented in `data.py`.\n", "- `Trainer`. It is a class, which manages training loop and dedicated stuff, like checkpointing, earlystopping and so on. It is pre-configured for you, so that\n", "    - It stops training, when validation loss starts to rise\n", "    - Every 10 steps of training it stops, calculaties min loss on the whole validation dataset and logs it to tensorboard.\n", "    - It implements a progress bar to monitor progress\n", "- `Model` (`MNISTEncoderDecoder`). This is a class, which collects methods dedicated to work with a model. It is implemented if `model.py`, you'll further need to write a part of it.\n", "    - It is initialize with quantizer and vq_loss, which we'll implement further.\n", "    - You usually understand, what happen's in its methods by the name.\n", "    - It has an inherited `self.log(\"name\", metric)` method for convinient logging of metrics. Majority of logging is implemented for you.\n", "\n", "Let's initialize those methods and train basic encoder decoder."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["datamodule = MNISTDataModule(data_dir=data_path, batch_size=256)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_trainer():\n", "    earlystopping = EarlyStopping(monitor=\"val/loss\")\n", "    checkpoint = ModelCheckpoint(dirpath=data_path / \"model\", save_top_k=2, monitor=\"val/loss\")\n", "\n", "    trainer = L.Trainer(\n", "        callbacks=[earlystopping, checkpoint],\n", "        devices=[device_id],\n", "        check_val_every_n_epoch=1,\n", "        max_epochs=30,\n", "        enable_progress_bar=True,\n", "        enable_checkpointing=True,\n", "        num_sanity_val_steps=0,\n", "        default_root_dir=data_path / \"model\",\n", "        log_every_n_steps=10,\n", "        # gradient_clip_val=0.1,\n", "    )\n", "    return trainer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainer = get_trainer()\n", "model = MNISTEncoderDecoder(quantizer=None, vq_loss=None)\n", "trainer.fit(model=model, datamodule=datamodule)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now go to the tensorboard and make sure that you are able to monitor metrics and see the pictures of generated images."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# %tensorboard --logdir str(data_path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2. Vector quantisation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Assignment: go to vector_quantisation.py\n", "# Implement the missed methods in VectorQuantisation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["assert test_vector_quantization()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok, now as we've implemented the VectorQuantisation class, we need to train it.\n", "Training Vector Quantisation is not the obvious part.\n", "There are three losses to make it work:\n", "1. ***Reconstruction loss.***\n", "This loss is is between our predicted picture and target image.\n", "In our case it  is MSELoss.\n", "The tricky thing with this loss is that its gradients should propogate over decoder and encoder.\n", "When we train with vector quantisation, the loss is lost when we pick vectors from the codebook.\n", "That's why we need to explicitely copy gradients from decoder to encoder.\n", "2. ***Quantisation loss.***\n", "This loss forces vectors from embedding to be more alike vectors from the encoder.\n", "This is is MSELoss between vectors from encoder and quantized vectors. But it should propagate only to quantizer.\n", "3. ***Commitment loss.***\n", "This loss forces encoder to predict vectors more alike vectors from the codebook.\n", "This loss should propogate only to encoder. \n", "\n", "Let's write a Loss class, which collects second and third part of the whole loss. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODO: Very nice picture"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Assignment: implement vector_quantization.VectorQuantizationLoss.forward method"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["assert test_vector_quantisation_loss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now the tricky part: we should implement the forward method."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Assignment: implement model.MNISTEncoderDecoder.training_step_with_quantizer method"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["assert test_training_step()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we are ready to train a model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainer = get_trainer()\n", "quantizer = VectorQuantizer(codebook_size=16, embedding_dim=16)\n", "model = MNISTEncoderDecoder(quantizer=quantizer, vq_loss=VectorQuantizationLoss())\n", "trainer.fit(model=model, datamodule=datamodule)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3. Residual vector quantisation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we have significantly restricted the complexity of ways, how the network can compress the images. Previously it was a continuous embedding, now it is a restricted amount of inegers.\n", "We can increase the amount of possible encodings, while maintaining the amoubnt of used vectors.\n", "\n", "For this purpose we'll use residual vecotr quantisation (RVQ).\n", "We'll use several quantisers, let's say $N$.\n", "The first quantiser encodes each vector as usual.\n", "Second quantiser encodes the residaul between the ground-truth vector and first quantised vector.\n", "Third quantiser encodes the residual between the ground-truth vector and sum of first and second quantisers.\n", "And so on.\n", "Now instead of encoding vector by $1$ index from a single codebook, we encode each vector by $N$ integers, each one represent the index from the dedicated codebook.\n", "\n", "![rvq.png](pictures/rvq.png)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Assignment: implement vector_quantization.ResidualVectorQuantizer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's train the model and see, how the prediction changes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainer = get_trainer()\n", "quantizer = ResidualVectorQuantizer(codebook_size=4, embedding_dim=16, n_codebooks=4)\n", "model = MNISTEncoderDecoder(quantizer=quantizer, vq_loss=VectorQuantizationLoss())\n", "trainer.fit(model=model, datamodule=datamodule)"]}], "metadata": {"kernelspec": {"display_name": "course", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.18"}}, "nbformat": 4, "nbformat_minor": 2}